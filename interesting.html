<!DOCTYPE html>
<html>
    <head>
        <title>russelltankaimin-interesting</title>
        <meta charset="UTF-8">
        <link rel="stylesheet" href="styles.css">
    </head>
    <body>
        <p>This is a collection of interesting articles and research papers to read. It is not limited to science or mathematics.</p>
        <ul>
            <li>
                <p class="title">Title: Crystalball: Gazing in the Black Box of SAT Solving
                    <a href="https://www.msoos.org/wordpress/wp-content/uploads/2019/06/sat19-skm.pdf">paper</a>
                </p>
                <p class="author">Authors : Mate Soos, Raghav Kulkarni, Kuldeep S. Meel</p>
                <p class="description">Short Description : The main paper which I consulted during my internship at DSO before university. This paper introduces the Crystalball framework in SAT solving. Essentially, we view SAT solvers as a composition of classifiers and regressors for different tasks such as branching, clause memory management and restarting. This paper opened my eyes to the combination of artificial intelligence and SAT solving.
                    UNSAT instances will generate a proof of unsatisfiability and this proof contains a bunch of lemmas and deletion clauses. The lemmas consume a large part of memory and some are discarded after a few iterations which resulted in the deletion clauses in the proofs. However, this paper suggested another different approach which collected data of each lemma during the solving process and use
                    the data collected to train a Decision Tree classifier to decide which lemmas to throw away or keep instead of letting it sit in the lemma database. The SAT solver (Cryptominisat) then recompiles to a machine learning model and this speeds up the time taken to determing unsatisfiability. This paper also allows us to see into the black box of SAT solving.
                </p>
            </li>
            <li>
                <p class="title">Title: Bosphorus : Bridging ANF and CNF Solvers
                    <a href = "https://www.comp.nus.edu.sg/~meel/Papers/date-cscm19.pdf">paper</a>
                </p>
                <p class="author">Authors : Davin Choo
                    , Mate Soos
                    , Kian Ming A. Chai
                    , and Kuldeep S. Meel</p>
                <p class="description">Short Description : Algebraic Normal Form (ANF) and Conjunctive
                    Normal Form (CNF) are commonly used to encode problems
                    in Boolean algebra. ANFs are typically solved via Grobner ¨
                    basis algorithms, often using more memory than is feasible;
                    while CNFs are solved using SAT solvers, which cannot exploit
                    the algebra of polynomials naturally. A paradigm
                    that bridges between ANF and CNF solving techniques is proposed: the
                    techniques are applied in an iterative manner to learn facts
                    to augment the original problems. (Adapted from the paper's abstract)</p>
            </li>
            <li>
                <p class="title">Title : FermiNet : Quantum Physics and Chemistry from First Principles
                <a href = "https://deepmind.com/blog/article/FermiNet">Blog Post</a>
                </p>
                <p class="author">Authors : Authors : David Pfau, 
                    James Spencer, Alexander Matthews, Matthew Foulkes</p>
                <p class="description">Short Description : FermiNet demonstrates the power of Deep Learning in helping us compute the energy of atoms
                     and molecules from first principles which can help to solve the fundamental equations for Quantum Mechanics for real-world systems. 
                     It can potentially allow researchers to create new materials and advance our understanding of the mysterious realm of Quantum Mechanics.
                    </p>
            </li>
            <li>
                <p class="title">Title : Game theory as an engine for large-scale data analysis
                    <a href = "https://deepmind.com/blog/article/EigenGame">Blog Post</a>
                </p>
                <p class="author">Authors : Brian Mcwilliams, Ian Gemp, Claire Vernade</p>
                <p class="description">Short Description : This blog shows us a very novel application of Principal Component analysis
                    (PCA) as a multi-agent game called EigenGame. PCA is generally known as a dimensionality reduction tool for machine learning
                    models to learn lower dimensional representations of datasets. Moreover, it shares a common aspect with a lot of machine learning
                    tools : Singular Value Decomposition(SVD). In EigenGame each player controls an eigenvector. Players increase their score by explaining 
                    variance within the data but are penalised if they’re too closely aligned to other players. We also establish a hierarchy: Player 1 only cares
                    about maximising variance, whereas other players also have to worry about minimising their alignment with players above them in the hierarchy. 
                    This combination of rewards and penalties defines each player’s utility. If all players play optimally, then they would have achieved Nash's Equilibrium.
                    This can be achieved if each player maximises their utility independently and simultaneously using gradient ascent. (Some portions adapted from the blog post)
                </p>
            </li>
            <li>
                <a href = "https://ieeexplore.ieee.org/document/747127">The implementation of partial least squares with artificial neural network architecture</a>
            </li>
            <li>
                <a href="https://arxiv.org/abs/1706.03762">Attention is all you need</a>
            </li>
            <li>
                <a href="https://www.researchgate.net/publication/220944429_Extending_SAT_Solvers_to_Cryptographic_Problems">Extending SAT_Solvers to Cryptographic Problems</a>
            </li>
            <li>
                <a href = "https://arxiv.org/abs/2106.00120">Probabilistic Deep Learning with Probabilistic Neural Networks and Deep Probabilistic Models</a>
            </li>
        </ul>
    </body>
</html>